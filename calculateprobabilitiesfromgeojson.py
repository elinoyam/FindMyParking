# -*- coding: utf-8 -*-
"""CalculateProbabilitiesFromGeojson.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/elinoyam/FindMyParking/blob/WorkingWithColab/CalculateProbabilitiesFromGeojson.ipynb
"""

import json

# import geojson as geojson
# import pip
import requests
import numpy as np
# import sqlalchemy as sqlalchemy
# !pip install geojson
import geojson

# Commented out IPython magic to ensure Python compatibility.
# from google.colab import drive
# drive.mount('/content/drive')
# change this
# %cd /content/drive/MyDrive/Colab Notebooks/Find My Parking/

# pip install sqlalchemy-utils
from sqlalchemy_utils import database_exists, create_database
from sqlalchemy import create_engine, MetaData, Table, Column, Integer, Float, insert, delete, update, text

my_conn = create_engine("sqlite:///my_db.db")

if not database_exists(my_conn.url):
    create_database(my_conn.url)
meta = MetaData()
parking_data_table = Table(
    'parking_data', meta,
    Column('node_id', Integer, primary_key=True),
    Column('free_count', Integer),
    Column('occupied_count', Integer),
    Column('probability', Float)
)
meta.create_all(my_conn)


# my_conn.execute('''
# CREATE TABLE IF NOT EXISTS my_db.test
# (
#   node_id INT,
#   free_parkings INT,
#   occupied_parkings INT,
#   probability DECIMAL(18,4)
# )
#  ''')
#

def find_osm_node_id(coordinate):
    lat = coordinate[0]
    lon = coordinate[1]
    # get the way id - request json format of the reverse method of OSM librery nominatim
    request_url = "https://nominatim.openstreetmap.org/reverse?format=geojson&osm_type=N&lat=" + f'{lat:f}' + "&lon=" + f'{lon:f}'
    # print(request_url)
    response = requests.get(request_url)
    way_id_response = json.loads(response.text)
    # print(way_id_response)
    osm_type = way_id_response['features'][0]['properties']['osm_type']
    node_id = way_id_response['features'][0]['properties']['osm_id']
    if osm_type != "node":
        print("not node: " + str(node_id))
        # print(node_id)

    return node_id

def calculate_coords(list_of_old_coorinates):
    data = [f"{point[0]},{point[1]}" for point in list_of_old_coorinates]
    data = ";".join(data)
    request_url = f"https://epsg.io/trans?data={data}&s_srs=25833&&t_srs=4326"
    response = requests.get(request_url)
    transform_coordinates_response = json.loads(response.text)
    transformed_coordinates = [[float(dict["y"]), float(dict["x"])] for dict in transform_coordinates_response]

    return transformed_coordinates

# def calculate_coords(list_of_old_coorinates):
#     transformed_coordinates = []
#     for old_cord in list_of_old_coorinates:
#         old_lat = old_cord[0]
#         old_lon = old_cord[1]
#         # get the latitude and longitude in the right coordinates
#         # from the original format EPSG:25833 to format: EPSG:4326
#         request_url = "https://epsg.io/trans?s_srs=25833&t_srs=4326&x=" + str(old_lat) + "&y=" + str(old_lon)
#         response = requests.get(request_url)
#         transform_coordinates_response = json.loads(response.text)
#         trans_lon = transform_coordinates_response['x']
#         trans_lat = transform_coordinates_response['y']
#         transformed_coordinates.append([float(trans_lat), float(trans_lon)])
#
#     return transformed_coordinates


def transform_line(line):
    old_coords = line['geometry']['coordinates'][0][0]
    transformed_coords = calculate_coords(old_coords)
    osm_id = find_osm_node_id(transformed_coords[0])
    # calculate parking area
    all_lats = [x for x, y in transformed_coords]
    all_lons = [y for x, y in transformed_coords]
    parking_area = polygon_area(all_lats, all_lons)  # we multiply by 1000 to convet to m2 instead of km2
    # calculate number of parking spots in the parking area
    single_parking_area = 4.88 * 2.44
    number_of_parking = parking_area / single_parking_area
    # print(number_of_parking)
    # get the label (parking empty/occupied)
    line_label = line['properties']['label_x']

    return osm_id, line_label, number_of_parking


# line = '{ "type": "Feature", "properties": { "id": 1, "label_x": "PK-space-occupied", "True_or_False": null, "label_y": null, "nearest_geometry_dis": null, "parking_area_m2": null, "layer": "Annotaions Predictions", "path": "F:/Berlin-DOP_2020/Predictions/Previously created maps/Annotations/Annotaions.geojson" }, "geometry": { "type": "MultiPolygon", "coordinates": [ [ [ [ 391008.0878, 5821088.3568 ], [ 391002.407, 5821095.493 ], [ 391004.3319, 5821096.9484 ], [ 391009.8718, 5821089.4366 ], [ 391008.1817, 5821088.2629 ], [ 391008.0878, 5821088.3568 ] ] ] ] } }'
# #line = line.replace("null", "None")
# json_line = json.loads(line)
# transform_line(json_line)

# osm_id = find_osm_node_id([52.54203249, 13.41329482])
# print(osm_id)

# input_coord = [ [ 392395.9, 5822510.25 ], [ 392396.65, 5822510.8 ], [ 392398.25, 5822513.5 ], [ 392398.15, 5822513.8 ], [ 392397.6, 5822514.35 ], [ 392397.1, 5822514.65 ], [ 392396.6, 5822514.55 ], [ 392396.25, 5822514.2 ], [ 392395.15, 5822512.6 ], [ 392394.95, 5822512.1 ], [ 392394.95, 5822511.6 ], [ 392395.35, 5822510.7 ], [ 392395.9, 5822510.25 ]]

# output_coord = calculate_coords(input_coord)

# print(output_coord)

# for cord in output_coord:
#   found_id = find_osm_node_id(cord)
#   print(found_id)

# # first way to calculate area on the earth surface

# !pip install area
# from area import area
# poly_obj = {'type':'Polygon','coordinates':[[[52.54203249, 13.41329482], [52.54203758, 13.41330569], [52.54206216, 13.4133284], [52.54206483, 13.41332683], [52.54206967, 13.41331855], [52.54207226, 13.41331108], [52.54207127, 13.41330374], [52.54206805, 13.4132987], [52.54205346, 13.413283], [52.54204892, 13.41328021], [52.54204443, 13.41328038], [52.54203642, 13.41328656], [52.54203249, 13.41329482]]]}
# area(poly_obj)

# second (and more precise) way for calculating the area on earth surface

def polygon_area(lats, lons, radius=6378137):
    """
    Computes area of spherical polygon, assuming spherical Earth. 
    Returns result in ratio of the sphere's area if the radius is specified.
    Otherwise, in the units of provided radius.
    lats and lons are in degrees.
    """
    from numpy import arctan2, cos, sin, sqrt, pi, power, append, diff, deg2rad
    lats = np.deg2rad(lats)
    lons = np.deg2rad(lons)

    # Line integral based on Green's Theorem, assumes spherical Earth

    # close polygon
    if lats[0] != lats[-1]:
        lats = append(lats, lats[0])
        lons = append(lons, lons[0])

    # colatitudes relative to (0,0)
    a = sin(lats / 2) ** 2 + cos(lats) * sin(lons / 2) ** 2
    colat = 2 * arctan2(sqrt(a), sqrt(1 - a))

    # azimuths relative to (0,0)
    az = arctan2(cos(lats) * sin(lons), sin(lats)) % (2 * pi)

    # Calculate diffs
    # daz = diff(az) % (2*pi)
    daz = diff(az)
    daz = (daz + pi) % (2 * pi) - pi

    deltas = diff(colat) / 2
    colat = colat[0:-1] + deltas

    # Perform integral
    integrands = (1 - cos(colat)) * daz

    # Integrate 
    area = abs(sum(integrands)) / (4 * pi)

    area = min(area, 1 - area)
    if radius is not None:  # return in units of radius
        return area * 4 * pi * radius ** 2
    else:  # return in ratio of sphere total area
        return area


# from sqlalchemy.dialects.postgresql import insert
from sqlalchemy.dialects.sqlite import insert


def save_data_to_db(empty_count, occupied_count):
    # save all the empty data
    for node, count in empty_count.items():
        res = my_conn.execute(f'''select * from parking_data where node_id = {node}''').first()
        if not res:
            stmt = (insert(parking_data_table).values(node_id=node, free_count=count, occupied_count=0, probability=0))
        else:
            existing_count = res['free_count']
            stmt = (update(parking_data_table).where(parking_data_table.c.node_id == node).values(
                free_count=count + existing_count))
        my_conn.execute(stmt)
    # save all the occupied data
    for node, count in occupied_count.items():
        res = my_conn.execute(f'''select * from parking_data where node_id = {node}''').first()
        if not res:
            stmt = (insert(parking_data_table).values(node_id=node, free_count=0, occupied_count=count, probability=0))
        else:
            existing_count = res['occupied_count']
            stmt = (update(parking_data_table).where(parking_data_table.c.node_id == node).values(
                occupied_count=count + existing_count))
        my_conn.execute(stmt)


# emptty = {"123" : 10, "456" :20, "789" :5 }
# occ = {"123": 10, "789" :20}

# save_data_to_db(emptty, occ)

# res_table = my_conn.execute('''SELECT * FROM parking_data''', multi=True)
# for row in res_table:
#   print(row)

file_path = "parking01.geojson"
# count the parking spots members:
empty_pk_spots = {}
occupied_pk_spots = {}

# open the file using geojson (less updated)
with open(file_path) as f:
    data_file = geojson.load(f)
    features_array = data_file['features']

    i = 1
    for feature in features_array:
        node_id, label, amount = transform_line(feature)
        if label == 'PK-space-occupied':
            occupied_count = occupied_pk_spots.setdefault(node_id, 0)
            occupied_pk_spots[node_id] = occupied_count + amount
        elif label == 'PK-space-empty':
            empty_count = empty_pk_spots.setdefault(node_id, 0)
            empty_pk_spots[node_id] = empty_count + amount
        print(i)
        i += 1

print("empty:")
print(empty_pk_spots)
print("occupied:")
print(occupied_pk_spots)

save_data_to_db(empty_pk_spots, occupied_pk_spots)

res = my_conn.execute('''SELECT * FROM parking_data''')
for row in res:
    print(row)

# def get_prob_for_node(node_id, index):
#     # print('index = ' + str(index))
#     # print('node_id = ' + str(node_id))
#     f = open("probabilities.osm", "r")
#     flag=-1
#     for line in f.readlines():
#         if line.startswith('\t\t<nd ref'):
#             start_index = (line.index('=')) + 2 #the starting of the node_id number
#             end_index= (line.index('/')) -1            
#             if (line[start_index:end_index]) == node_id:
#               flag=0  # it means that the next tag we will see we will go inside
#         elif flag == 0 and line.startswith('\t\t<tag'):
#           start = line.index('v')
#           end = len(line) - 4
#           temp_list = line[start+3:end].split(',')
#           prob_list = [eval(i) for i in temp_list]
#           print('prob_list = ' + str(prob_list))
#           print('prob_list value = ' + str(prob_list[index]))
#           return prob_list[index]
#     return 0 #if didn't find- return 0

# def most_common_highest_probability():
#     file = open("probabilities.osm", "r")
#     bucket_list = [0] * 168 # 24 * 7
#     for line in file.readlines():
#         if line.startswith('\t\t<tag'):
#             index = line.index('v')
#             end = len(line) - line[::-1].index('"') -1
#             temp_list = line[index+3:end].split(',')
#             for index in range(len(temp_list)):
#                 if temp_list[index] not in ['', '0']:
#                     bucket_list[index] += 1
#     print('bucket_list = ' + str(bucket_list))
#     return bucket_list.index(max(bucket_list))

# def prepare_data_for_model():
#   data_list=[]
#   relevant_index= most_common_highest_probability()
#   for node_id in empty_pk_spots.keys():
#     num_of_empty= empty_pk_spots[node_id]
#     if node_id in occupied_pk_spots:
#       num_of_occupied= occupied_pk_spots[node_id]
#     else:
#       num_of_occupied=0
#     prob_for_empty_parking= get_prob_for_node(node_id, relevant_index)
#     data_list.append([num_of_empty, num_of_occupied, prob_for_empty_parking])

#   for node_id in occupied_pk_spots.keys():
#     if node_id not in empty_pk_spots: # so we didn't go through it yet and the probability is 0
#       prob_for_empty_parking= get_prob_for_node(node_id, relevant_index)
#       data_list.append([0, occupied_pk_spots[node_id], prob_for_empty_parking])

#   return data_list

# data = prepare_data_for_model()
# print(data)
